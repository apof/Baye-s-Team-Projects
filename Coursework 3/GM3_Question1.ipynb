{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "## Question 1\n",
    "### part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.array([[1,1,1,1,0,0],[0,0,1,1,0,1], [1,0,0,1,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_encoding(H):\n",
    "    n_rows, n_columns = H.shape\n",
    "    H_hat = np.zeros((H.shape))\n",
    "    \n",
    "    for i in range(n_columns):\n",
    "        H_hat[:,i] = H[:, i]\n",
    "     \n",
    "    for j in range(n_rows):\n",
    "        found = False\n",
    "        dummy = np.zeros((H.shape))\n",
    "        for i in range(n_columns):\n",
    "            if (np.sum(H_hat[:,i]) == 1) & (H_hat[j,i] == 1) & (found==False):\n",
    "                dummy[:,n_columns-n_rows+j] = H_hat[:,i].T\n",
    "                dummy[:,i] = H_hat[:, n_columns-n_rows+j]\n",
    "                found = True\n",
    "                    \n",
    "            elif np.sum(dummy[:,i]) == 0:\n",
    "                dummy[:,i] = H_hat[:,i]\n",
    "        \n",
    "        H_hat = dummy\n",
    "    \n",
    "            \n",
    "    G = np.zeros((n_columns, n_columns-n_rows))\n",
    "    G[:n_columns - n_rows, :n_columns - n_rows] = np.eye(N=n_columns-n_rows)\n",
    "    G[n_columns - n_rows:, :n_columns - n_rows] = H_hat[:, :n_columns-n_rows]\n",
    "    return H_hat, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,0,1,0,0,1], [0,1,1,0,0,1], [0,0,0,0,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[1,1,0,1,0,0], [0,0,1,1,0,0], [1,0,0,1,1,0], [0,0,0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([[1,1,0,0,1,0],[1,1,0,0,0,1],[1,0,0,1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0]\n",
      " [0 0 1 1 0 1]\n",
      " [1 0 0 1 1 0]]\n",
      "\n",
      "\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(H)\n",
    "print('\\n')\n",
    "H_bar,G_bar = system_encoding(H)\n",
    "print(H_bar)\n",
    "print('\\n')\n",
    "print(G_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(H_bar@G_bar@np.array([0,0,0]).T)%2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 1]\n",
      " [0 1 1 0 0 1]\n",
      " [0 0 0 0 1 1]]\n",
      "\n",
      "\n",
      "[[0. 1. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print('\\n')\n",
    "H_bar,G_bar = system_encoding(A)\n",
    "print(H_bar)\n",
    "print('\\n')\n",
    "print(G_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 0]\n",
      " [0 0 1 1 0 0]\n",
      " [1 0 0 1 1 0]\n",
      " [0 0 0 0 0 1]]\n",
      "\n",
      "\n",
      "[[1. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 1.]\n",
      " [0. 1.]\n",
      " [1. 1.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(B)\n",
    "print('\\n')\n",
    "H_bar,G_bar = system_encoding(B)\n",
    "print(H_bar)\n",
    "print('\\n')\n",
    "print(G_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 1 0]\n",
      " [1 1 0 0 0 1]\n",
      " [1 0 0 1 0 0]]\n",
      "\n",
      "\n",
      "[[1. 1. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(C)\n",
    "print('\\n')\n",
    "H_bar,G_bar = system_encoding(C)\n",
    "print(H_bar)\n",
    "print('\\n')\n",
    "print(G_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 0]\n",
      " [0 0 1 1 0 1]\n",
      " [0 0 0 1 1 0]]\n",
      "\n",
      "\n",
      "[[1. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "D = np.array([[1,1,0,1,0,0],[0,0,1,1,0,1], [0,0,0,1,1,0]])\n",
    "print(D)\n",
    "print('\\n')\n",
    "H_bar,G_bar = system_encoding(D)\n",
    "print(H_bar)\n",
    "print('\\n')\n",
    "print(G_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('H1.txt', 'r') as f:\n",
    "    H1 = [[int(num) for num in line.split(' ')] for line in f]\n",
    "H1 = np.array(H1)\n",
    "\n",
    "with open('y1.txt', 'r') as f:\n",
    "    y1 = [[int(num) for num in line.split(' ')] for line in f]\n",
    "y1 = np.array(y1)   \n",
    "H1_hat, G1 = system_encoding(H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(H1.shape)\n",
    "#print(G1.shape)\n",
    "#print(np.sum(H1_hat))\n",
    "#print(np.sum(H1_hat,axis=0)%2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 1], [0, 1, 0, 0], [0, 1, 0, 1], [0, 1, 1, 0], [0, 1, 1, 1], [1, 0, 0, 0], [1, 0, 0, 1], [1, 0, 1, 0], [1, 0, 1, 1], [1, 1, 0, 0], [1, 1, 0, 1], [1, 1, 1, 0], [1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "bin_seq = []\n",
    "\n",
    "def genbin(n, bs = ''):\n",
    "    if n-1:\n",
    "        bs0 = bs+'0'#.append(0)\n",
    "        bs1 = bs+'1' #.append(1)\n",
    "        genbin(n-1, bs0)\n",
    "        genbin(n-1, bs1)\n",
    "    else:\n",
    "        bin_seq.append([int(i) for i in bs])\n",
    "\n",
    "genbin(5)\n",
    "print(bin_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perms(n):\n",
    "    if not n:\n",
    "        return\n",
    "\n",
    "    for i in range(2**n):\n",
    "        s = bin(i)[2:]\n",
    "        s = \"0\" * (n-len(s)) + s\n",
    "        yield s\n",
    "\n",
    "#print(list(perms(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genBinary(n, i, pos_i):\n",
    "    #generates binary sequences of length n for an i in pos_i position\n",
    "    bin_seq = []\n",
    "    for item in list(perms(n)):\n",
    "        bin_seq.append([int(i) for i in item])\n",
    "        \n",
    "    sequence = np.array(bin_seq)\n",
    "    \n",
    "    sequence[:, pos_i] = i*np.ones((1,2**(n)))\n",
    "    \n",
    "    \n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ldpc_decoder(H_hat, y, p, max_iter = 20):\n",
    "    # This function should be used to do loopy belief propogation on our recieved signal y and return a vector\n",
    "    # which reperesents the decoded output message.\n",
    "    # This function should work on the assumption we using the Binary symetric channel\n",
    "    # It should also output a zero if the a solution was reached and algorithm converged and -1 if it is not.\n",
    "    \n",
    "    # Going to need to set up priors and messages which are going to be sent around the system \n",
    "    \n",
    "    n_rows, n_cols = H_hat.shape\n",
    "    \n",
    "    # n_rows is the number of partity checks we have and therefore factors in our graph \n",
    "    # So we need to go over the iterations and do a pass throuhg the whole system\n",
    "    # n_cols is the number of features we have \n",
    "    \n",
    "    # 1) Initialise (outside for loop) - p(yn|xn)\n",
    "    # 2) Factor to variable messages\n",
    "    # 3) Variable to factor messages\n",
    "    # 4) Calculate marginals - go back through the steps after this\n",
    "    \n",
    "    initials = np.zeros((2, n_cols))\n",
    "    \n",
    "    #Here compute the initail probs P(yn|xn) for each value of xn and given yn values (these are first var to factor messages)\n",
    "    for n in range(n_cols):\n",
    "        for i in range(2):\n",
    "            initials[i,n] = p**((i-y[n,0])%2)*(1-p)**((i-y[n,0]+1)%2)\n",
    "    \n",
    "    #Define a dictionary has each variable and the checks associatied with it\n",
    "    variables_and_checks = {}\n",
    "    checks_and_variables = {}\n",
    "    #cylce over variables\n",
    "    for n in range(n_cols):\n",
    "        #cycle of checks\n",
    "        for m in range(n_rows):\n",
    "            if H_hat[m,n] == 1 and (n not in variables_and_checks):\n",
    "                variables_and_checks[n] = [m]\n",
    "            elif H_hat[m,n] == 1:\n",
    "                variables_and_checks[n].append(m)\n",
    "                \n",
    "            if H_hat[m,n] == 1 and (m not in checks_and_variables):\n",
    "                checks_and_variables[m] = [n]\n",
    "            elif H_hat[m,n] == 1:\n",
    "                checks_and_variables[m].append(n)\n",
    "                \n",
    "    #print(variables_and_checks)\n",
    "    #print(checks_and_variables)\n",
    "    \n",
    "    #Marginals - initialise the marginals that will beproduced at each each iteration\n",
    "    marginals = {}\n",
    "    \n",
    "    #Intitalise the factor to variable messages\n",
    "    messages_fv = {}\n",
    "    \n",
    "    #Initialise the variable to factor messages\n",
    "    messages_vf = {}\n",
    "    \n",
    "    # Now we go through each iteration and doing all message passing\n",
    "    for iTer in range(max_iter):\n",
    "        \n",
    "        # We compute factor to variable messages based off the parity check matrix\n",
    "        for n in range(n_cols):\n",
    "            mess = np.zeros((2, len(variables_and_checks[n])))\n",
    "            # Now lets loop through the checks we need to do\n",
    "            for check in variables_and_checks[n]:\n",
    "                # loop through the possible values of our variable and generate tbe messages assoicated with it.\n",
    "                for i in range(2):\n",
    "                    # The number of varlues in this parity check are as follows\n",
    "                    num_parity_bits = len(checks_and_variables[check])\n",
    "                    \n",
    "                    tries = genBinary(num_parity_bits, i, checks_and_variables[check].index(n))\n",
    "                    \n",
    "                    for row in range(tries.shape[0]):\n",
    "                        if np.sum(tries[row,:])%2 == 0:\n",
    "                            product = 1\n",
    "                            for num in range(len(tries[row,:])): \n",
    "                                if checks_and_variables[check][num]!= n:\n",
    "                                    # Times by the associated messages.\n",
    "                                    \n",
    "                                    product *= initials[tries[row,num],checks_and_variables[check][num]]\n",
    "                                    \n",
    "                            mess[i, variables_and_checks[n].index(check)] += product\n",
    "                                    \n",
    "            messages_fv[n] = mess\n",
    "            \n",
    "        #Now we want to compute all messages from variables to factors\n",
    "        \n",
    "        #Cycle over all factors\n",
    "        for m in range(n_rows):\n",
    "            #intiialise the matrix of all variables associated with the factor\n",
    "            mess = np.zeros((2, len(checks_and_variables[m])))\n",
    "            \n",
    "            for var in checks_and_variables[m]:\n",
    "                 for i in range(2):\n",
    "                        # initialise with P(yn|xn)\n",
    "                        mess[i,checks_and_variables[m].index(var)] = initials[i, var]\n",
    "                        # Now multiple by the messages from factors to that variable\n",
    "                        \n",
    "                        for num in range(len(variables_and_checks[var])):\n",
    "                            if variables_and_checks[var][num] != m:\n",
    "                                mess[i,checks_and_variables[m].index(var)] *= messages_fv[var][i,num]\n",
    "                                \n",
    "            messages_vf[m] = mess\n",
    "                                \n",
    "                                \n",
    "    # Next need to compute marginals                    \n",
    "                        \n",
    "            \n",
    "    print(messages_fv)\n",
    "    print(messages_vf)\n",
    "              \n",
    "    return initials\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ldpc_decoder(H1, y1, p, max_iter = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsc_noiser(x, p):\n",
    "    # This function takes in a message x and puts it through a noisy channel outputting the noisey version\n",
    "    y = np.zeros((x.shape))\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        ran_num = np.random.rand()\n",
    "        if ran_num <= p:\n",
    "            y[i,0] = (x[i,0]+1)%2\n",
    "        else:\n",
    "            y[i,0] = x[i,0]\n",
    "            \n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 1. 1. 1.]]\n",
      "[[0. 1. 0. 1. 1. 1.]]\n",
      "{0: array([[1.512, 1.64 ],\n",
      "       [0.488, 0.36 ]]), 1: array([[0.488],\n",
      "       [1.512]]), 2: array([[1.512, 1.64 ],\n",
      "       [0.488, 0.36 ]]), 3: array([[0.488, 0.36 , 0.36 ],\n",
      "       [1.512, 1.64 , 1.64 ]]), 4: array([[0.36],\n",
      "       [1.64]]), 5: array([[0.36],\n",
      "       [1.64]])}\n",
      "{0: array([[1.476  , 0.1    , 1.476  , 0.01296],\n",
      "       [0.036  , 0.9    , 0.036  , 2.42064]]), 1: array([[1.3608  , 0.017568, 0.1     ],\n",
      "       [0.0488  , 2.231712, 0.9     ]]), 2: array([[1.3608  , 0.017568, 0.1     ],\n",
      "       [0.0488  , 2.231712, 0.9     ]])}\n",
      "[[0.9 0.1 0.9 0.1 0.1 0.1]\n",
      " [0.1 0.9 0.1 0.9 0.9 0.9]]\n"
     ]
    }
   ],
   "source": [
    "H = np.array([[1,1,1,1,0,0],[0,0,1,1,0,1], [1,0,0,1,1,0]])\n",
    "\n",
    "p = 0.1\n",
    "\n",
    "x = np.array([[0],[1],[0]])\n",
    "\n",
    "H_hat, G = system_encoding(H)\n",
    "\n",
    "message =G@x\n",
    "\n",
    "signal = bsc_noiser(message, p)\n",
    "\n",
    "print(message.T)\n",
    "print(signal.T)\n",
    "\n",
    "decoded_message = ldpc_decoder(H, signal, p)\n",
    "print(decoded_message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
