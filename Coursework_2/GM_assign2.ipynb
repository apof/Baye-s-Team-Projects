{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max likelihood estimation\n",
    "In this case we need to add up the times it swithced between a the states.\n",
    "\n",
    "Questions: I have summed over all rows and columns this may not be true? do we do one then the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "T = 100\n",
    "\n",
    "data_file = 'meteo0.csv'\n",
    "data = np.ones((N, T))\n",
    "with open(data_file) as csvDataFile:\n",
    "    csvReader = csv.reader(csvDataFile, delimiter =' ')\n",
    "    count=0\n",
    "    for row in csvReader:\n",
    "        for n in range(len(row)):\n",
    "            data[count, n] = row[n]\n",
    "        count +=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 256 90\n",
      "[0.308, 0.512, 0.18]\n"
     ]
    }
   ],
   "source": [
    "p_v1_0 = np.sum([data[:,0] == 0])\n",
    "p_v1_1 = np.sum([data[:,0] == 1])\n",
    "p_v1_2 = np.sum([data[:,0] == 2])\n",
    "print(p_v1_0, p_v1_1,p_v1_2)\n",
    "\n",
    "p_v1 = [p_v1_0/N, p_v1_1/N, p_v1_2/N]\n",
    "print(p_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7        0.16831816 0.        ]\n",
      " [0.18102894 0.70075775 0.30236498]\n",
      " [0.11897106 0.13092409 0.69763502]]\n"
     ]
    }
   ],
   "source": [
    "### p(vt+1 = 0| vt =1)\n",
    "A = np.zeros((3,3))\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(T-1):\n",
    "        A[int(data[i,j]), int(data[i,j+1])] += 1/N\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    A[:,i] = A[:,i]/np.sum(A[:,i])\n",
    "\n",
    "print(A)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "forward backward algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.        ]\n",
      " [1.         0.        ]\n",
      " [0.50239234 0.49760766]\n",
      " [0.29824561 0.70175439]\n",
      " [0.73205742 0.26794258]\n",
      " [0.17065391 0.82934609]\n",
      " [1.         0.        ]\n",
      " [0.48837209 0.51162791]\n",
      " [0.34108527 0.65891473]\n",
      " [0.59302326 0.40697674]]\n"
     ]
    }
   ],
   "source": [
    "V = np.array([0, 1, 0, 2, 0, 2, 1, 0, 2, 0])\n",
    "#Emmission\n",
    "A = np.array([[0.3, 0.5], [0.6,0],[0.1,0.5]])\n",
    "#Transition\n",
    "T = np.array([[0.5,0.8], [0.5, 0.2]])\n",
    "\n",
    "initial_dist = np.array([[1,0]])\n",
    "\n",
    "\n",
    "def forward(V, A, T, initial_dist):\n",
    "    alpha = np.zeros((V.shape[0], T.shape[0]))\n",
    "    alpha[0,:] = initial_dist*A[V[0],:]\n",
    "    alpha[0,:] = alpha[0,:]/np.sum(alpha[0,:])\n",
    "    \n",
    "    for t in range(1, V.shape[0]):\n",
    "        for j in range(T.shape[0]):\n",
    "            alpha[t,j] = alpha[t-1]@T[j,:]*A[V[t], j]\n",
    "        \n",
    "        alpha[t,:] = alpha[t,:]/np.sum(alpha[t,:])\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "alpha = forward(V,A,T, initial_dist)\n",
    "\n",
    "def backward(V, A, T):\n",
    "    beta = np.zeros((V.shape[0], T.shape[0]))\n",
    "    beta[V.shape[0] - 1,:] = np.ones((T.shape[0]))\n",
    "    beta[V.shape[0] - 1,:] = beta[V.shape[0] - 1,:]/np.sum(beta[V.shape[0] - 1,:])\n",
    "    \n",
    "    for t in range(V.shape[0] -2, -1, -1):\n",
    "        for j in range(T.shape[0]):\n",
    "            beta[t,j]=(beta[t+1]* A[V[t+1],:])@T[:,j]\n",
    "    \n",
    "        beta[t,:] = beta[t,:]/np.sum(beta[t,:])\n",
    "    return beta\n",
    "\n",
    "beta = backward(V,A,T)\n",
    "\n",
    "p_ht = np.zeros((T.shape[0],V.shape[0]))\n",
    "\n",
    "for t in range(0,V.shape[0]):\n",
    "    p_ht[0,t] = alpha[t,0]*beta[t,0] #*A[V[t],0]\n",
    "    p_ht[1,t] = alpha[t,1]*beta[t,1] #*A[V[t],1]\n",
    "\n",
    "\n",
    "p_ht = (p_ht/np.sum(p_ht, axis = 0)).T\n",
    "print(p_ht)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "p_h1_h2 = np.zeros(T.shape)\n",
    "p_h4_h5 = np.zeros(T.shape)\n",
    "\n",
    "for i in range(p_h1_h2.shape[0]):\n",
    "    for j in range(p_h1_h2.shape[1]):\n",
    "        p_h1_h2[i,j] = alpha[0,i]* beta[1, j]*T[i,j]*A[V[1],j] #*A[V[0],i]\n",
    "        p_h4_h5[i,j] = alpha[3,i]* beta[4, j]*T[i,j]*A[V[4],j] #*A[V[3],i]\n",
    "\n",
    "p_h1_h2=p_h1_h2/np.sum(p_h1_h2)\n",
    "print(np.sum(np.sum(p_h1_h2)))\n",
    "p_h4_h5 = p_h4_h5/np.sum(p_h4_h5)\n",
    "print(np.sum(np.sum(p_h4_h5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like(x):\n",
    "    c=x.max()\n",
    "    return c + np.log2(np.sum(np.exp(x-c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcLogLike(V, A, TEst, initial_dist):\n",
    "    \"\"\"\n",
    "    logLike = 0\n",
    "    like = np.zeros((2,len(V)))\n",
    "    \n",
    "    for t in range(len(V)):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                like\n",
    "    \n",
    "    \"\"\"\n",
    "    epsilon = 0.0001\n",
    "    logLike = 0\n",
    "    \n",
    "    for i in range(2):\n",
    "        if initial_dist[0, i]*A[V[0],i] > 0+epsilon:\n",
    "            logLike += np.log(initial_dist[0, i]*A[V[0],i])\n",
    "            \n",
    "    for t in range(1,len(V)):\n",
    "        for i in range(2):\n",
    "            if A[V[t],i]>0+epsilon:\n",
    "                logLike += np.log(A[V[t],i])\n",
    "            for j in range(2):\n",
    "                if TEst[i,j]>0+epsilon:\n",
    "                    logLike += np.log(TEst[i,j])\n",
    "    \n",
    "    logLike = log_like(logLike)\n",
    "    \n",
    "    \n",
    "    return logLike\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(data, A, initial_dist):\n",
    "    #Intialise transition matrxix to update\n",
    "    #T = np.array([[0.4,0.7], [0.6, 0.3]])\n",
    "    T = np.array([[0.5,0.8], [0.5, 0.2]])\n",
    "    ndata = data.shape[0]\n",
    "    \n",
    "    response = np.zeros((2,2,ndata))\n",
    "    \n",
    "    #response[:,0] = initial_dist[0]\n",
    "    loglikes=[]\n",
    "    \n",
    "    loglikes.append(calcLogLike(data, A, T, initial_dist))\n",
    "    #print(loglikes[0])\n",
    "    nIter = 0\n",
    "    running = True\n",
    "    while running:\n",
    "        #E step - update the probability distribtuion p(ht, ht+1|v, \\theta)\n",
    "        #Given the current T we want to update the posterior dist on hts\n",
    "        \n",
    "        alpha = forward(data, A, T, initial_dist)\n",
    "        beta = backward(data, A, T)\n",
    "        \n",
    "        \n",
    "        for t in range(0,ndata-1):\n",
    "            for i in range(2):\n",
    "                for j in range(2):\n",
    "                    response[i,j,t] = alpha[t,i]*beta[t+1, j]*T[i,j]*A[data[t+1],j] #*A[data[t],i]\n",
    "                    \n",
    "            summond = np.sum(response[:,:,t], axis=0)\n",
    "            summond[summond==0]=1\n",
    "            \n",
    "            response[:,:,t] = response[:,:,t]/summond\n",
    "\n",
    "        \n",
    "        #M step - update parameters for T\n",
    "        T_dum = np.zeros(T.shape)\n",
    "        \n",
    "        response_i = np.zeros((2, ndata))\n",
    "        \n",
    "        for t in range(ndata):\n",
    "            for j in range(2):\n",
    "                response_i[:,t] += response[:,j,t]\n",
    "            \n",
    "        \n",
    "        for i in range(2):\n",
    "            for j in range(2): \n",
    "                bottom = 0\n",
    "                top = 0\n",
    "                for t in range(0, ndata-1):\n",
    "                    top += response[i,j, t]\n",
    "                    bottom += response_i[i,t]\n",
    "                \n",
    "                T_dum[i,j] =  top/bottom                                   \n",
    "             \n",
    "        T_dum[:,0] = T_dum[:,0]/np.sum(T_dum[:,0]) \n",
    "        T_dum[:,1] = T_dum[:,1]/np.sum(T_dum[:,1])                                                \n",
    "        \n",
    "        \n",
    "        if (np.linalg.norm(T - T_dum)==0) or nIter == 120:\n",
    "            running =False\n",
    "        nIter += 1  \n",
    "        \n",
    "        T = T_dum\n",
    "        \n",
    "        #print(T)\n",
    "        loglike = calcLogLike(data, A, T, initial_dist)\n",
    "        #print(loglike)\n",
    "        loglikes.append(loglike)\n",
    "    \n",
    "    x = np.arange(nIter+1)\n",
    "    plt.plot(x,loglikes)\n",
    "    \n",
    "    print(nIter)\n",
    "    \n",
    "    return T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chess_results = []\n",
    "\n",
    "f = open('chess.txt', 'r')\n",
    "for item in f.read():\n",
    "    if item != '\\n':\n",
    "        chess_results.append(int(item))\n",
    "\n",
    "chess_results = np.array(chess_results) \n",
    "\n",
    "A = np.array([[0.3, 0.5], [0.6,0],[0.1,0.5]])\n",
    "\n",
    "initial_dist = np.array([[1,0]])\n",
    "\n",
    "forward(chess_results, A, np.array([[0.5,0.8], [0.5, 0.2]]), initial_dist)\n",
    "\n",
    "T = baum_welch(chess_results, A, initial_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.56261703 0.41859284]\n",
      " [0.43738297 0.58140716]]\n"
     ]
    }
   ],
   "source": [
    "print(T)\n",
    "#print(chess_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "a = forward(chess_results, A, T, initial_dist)\n",
    "b = backward(chess_results, A, T)\n",
    "V = chess_results\n",
    "\n",
    "p_h1000 =[]\n",
    "p_h1000.append(a[1000-1,0]*b[1000-1,0]*A[V[1000-1],0])\n",
    "p_h1000.append(a[1000-1,1]*b[1000-1,1]*A[V[1000-1],1])\n",
    "\n",
    "print(V[999])\n",
    "h1000 = np.argmax(p_h1000)\n",
    "print(h1000)\n",
    "h1001 = np.argmax(T[h1000,:])\n",
    "print(h1001)\n",
    "\n",
    "v1001 = np.argmax(A[:,h1001])\n",
    "print(v1001) #50 50 whether visible  is 0 or 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
